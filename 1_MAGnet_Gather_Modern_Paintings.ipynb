{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 MAGnet Gather Modern Paintings",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9oifn0dmNt+Wsx85GPD4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/MAGnet/blob/main/1_MAGnet_Gather_Modern_Paintings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZMf_VvYUDpM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMMlsgIB7jfY"
      },
      "source": [
        "file_path = \"/content/gdrive/MyDrive/modern_paintings\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD_7h5mc01N0"
      },
      "source": [
        "!mkdir $file_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-0JJXsS6PWY"
      },
      "source": [
        "import urllib\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "def get_images(url):\n",
        "  print(url)\n",
        "  genre_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
        "  artist_list_main = genre_soup.find(\"main\")\n",
        "  lis = artist_list_main.find_all(\"li\")\n",
        "\n",
        "  # for each list element\n",
        "  for li in lis: \n",
        "    born = 0\n",
        "    died = 0\n",
        "\n",
        "    # get the date range\n",
        "    for line in li.text.splitlines():\n",
        "      if line.startswith(\",\") and \"-\" in line:\n",
        "        parts = line.split('-')\n",
        "        if len(parts) == 2:\n",
        "          born = int(re.sub(\"[^0-9]\", \"\",parts[0]))\n",
        "          died = int(re.sub(\"[^0-9]\", \"\",parts[1]))\n",
        "\n",
        "    # look for artists who may have created work that could in public domain\n",
        "    if born>1800 and died>0 and died<1950:\n",
        "      link = li.find(\"a\")\n",
        "      artist = link.attrs[\"href\"]\n",
        "\n",
        "      # get the artist's main page\n",
        "      artist_url = base_url + artist\n",
        "      artist_soup = BeautifulSoup(urllib.request.urlopen(artist_url), \"lxml\")\n",
        "\n",
        "      # only look for artists with the word modern on their main page\n",
        "      if \"modern\" in artist_soup.text.lower():\n",
        "        print(artist + \" \" + str(born) + \" - \" + str(died))\n",
        "\n",
        "        # get the artist's web page for the artwork\n",
        "        url = base_url + artist + '/all-works/text-list'\n",
        "        artist_work_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
        "\n",
        "        # get the main section\n",
        "        artist_main = artist_work_soup.find(\"main\")\n",
        "        image_count = 0\n",
        "        artist_name = artist.split(\"/\")[2]\n",
        "\n",
        "        # get the list of artwork\n",
        "        lis = artist_main.find_all(\"li\")\n",
        "\n",
        "        # for each list element\n",
        "        for li in lis:\n",
        "          link = li.find(\"a\")\n",
        "\n",
        "          if link != None:\n",
        "            painting = link.attrs[\"href\"]\n",
        "\n",
        "            # get the painting\n",
        "            url = base_url + painting\n",
        "            print(url)\n",
        "\n",
        "            try:\n",
        "              painting_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
        "\n",
        "            except:\n",
        "              print(\"error retreiving page\")\n",
        "              continue\n",
        "\n",
        "            # check the copyright\n",
        "            if \"Public domain\" in painting_soup.text:\n",
        "\n",
        "              # get the url\n",
        "              og_image = painting_soup.find(\"meta\", {\"property\":\"og:image\"})\n",
        "              image_url = og_image[\"content\"].split(\"!\")[0] # ignore the !Large.jpg at the end\n",
        "              print(image_url)\n",
        "\n",
        "              parts = url.split(\"/\")\n",
        "              painting_name = parts[-1]\n",
        "              save_path = file_path + \"/\" + artist_name + \"_\" + painting_name + \".jpg\"\n",
        "\n",
        "              #download the file\n",
        "              try:\n",
        "                print(\"downloading to \" + save_path)\n",
        "                time.sleep(0.2)  # try not to get a 403                    \n",
        "                urllib.request.urlretrieve(image_url, save_path)\n",
        "                image_count = image_count + 1\n",
        "              except Exception as e:\n",
        "                print(\"failed downloading \" + image_url, e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoXxeuZjccOa"
      },
      "source": [
        "base_url = \"https://www.wikiart.org\"\n",
        "urls = []\n",
        "for c in range(ord('a'), ord('z') + 1):\n",
        "  char = chr(c)\n",
        "  artist_list_url = base_url + \"/en/Alphabet/\" + char + \"/text-list\"\n",
        "  urls.append(artist_list_url)\n",
        "\n",
        "print(urls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDZla14w7wL3"
      },
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "executor = None\n",
        "with ThreadPoolExecutor(max_workers = 8) as executor:\n",
        "  ex = executor\n",
        "  executor.map(get_images, urls)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}